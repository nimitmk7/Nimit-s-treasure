## What is Generative Modeling?

> Generative modeling is a branch of machine learning that involves training a model to produce new data that is similar to a given dataset.

**Example**:
Suppose we have a dataset containing photos of horses. We can train a generative model on this dataset to capture the rules that gov‐ ern the complex relationships between pixels in images of horses. Then we can sam‐ ple from this model to create novel, realistic images of horses that did not exist in the original dataset. 

![[Pasted image 20240531165200.png]]

In order to build a generative model, we require a dataset consisting of many examples of the entity we are trying to generate, which is **training data**, and one such data point is **observation**.

Each observation consists of many features. For an image generation problem, the features are usually the individual pixel values; for a text generation problem, the features could be individual words or groups of letters. 

**Goal**: Build a model that can generate new sets of features that look as if they have been created using the same rules as the original data. 

==A generative model must also be probabilistic rather than deterministic==, because we want to be able to sample many different variations of the output, rather than get the same output every time.

Therefore, a generative model must include a random component that influences the individual samples generated by the model. 

### Generative vs Discriminative Modeling

When performing discriminative modeling, each observation in the training data has a label. For a binary classification problem such as our artist discriminator, Van Gogh paintings would be labeled 1 and non–Van Gogh paintings labeled 0.

![[Pasted image 20240531165814.png]]
Our model then learns how to discriminate between these 2 groups and outputs the probability that a new observation has label 1 - i.e. that it was painted by Van Gogh.

In contrast, ==generative modeling doesn’t require the dataset to be labeled== because it concerns itself with generating entirely new images, rather than trying to predict a label of a given image.

> *Discriminative modeling* estimates $p(y|x)$. 
> 
> That is, discriminative modeling aims to model the probability of a label $y$ given some observation $x$.

> *Generative modeling* estimaters $p(x)$.
> 
> That is, generative modeling aims to model the probability of observing an observation $x$. Sampling from this distribution allows us to generate new observations.

> [!INFO] Conditional Generative Models
>  Note that we can also build a generative model to model the conditional probability $p(x|y)$ → the probability of seeing an observation $x$ with a label $y$.  
>  
>  For example, if our dataset contains different types of fruit, we could tell our generative model to specifically generate an image of an apple.

## Toy Generative Model

### Hello World!

Generative modeling game in 2D: 
Given a set of points $X$ in the figure generated by an unknown rule $p_{data}$ , choose a different point $x=(x_1, x_2)$ in the space that looks like it has been generated by the same rule. 

![[Pasted image 20240531200526.png]]

Where did you choose? You probably used your knowledge of the existing data points to construct a mental model, $p_{model}$, of whereabouts in the space the point is more likely to be found. In this respect, $p_{model}$ is an estimate of pdata. 

Perhaps you decided that $p_{model}$ should look like the next figure—a rectangular box where points may be found, and an area outside of the box where there is no chance of finding any points.

![[Pasted image 20240531200709.png]]
To generate a new observation, you can simply choose a point at random within the box, or more formally, sample from the distribution $p_{model}$. Congratulations, you have just built your first generative model! 

You have used the training data (the black points) to construct a model (the orange region) that you can easily sample from to generate other points that appear to belong to the training set.

### Generative Modeling Framework
- Dataset of observations $X$.
- Unknown distribution generating the data: $p_{data}$
- Our model to be built to mimic it: $p_{model}$
- If we achieve that, we can sample from $p_{model}$ to generate observations that appear to have been drawn from $p_{data}$.
- Desirable properties of $p_{model}$: 
	-  *Accuracy* : If $p_{model}$ is high for a generated observation, it should look like it has been drawn from $p_{data}$. If $p_{model}$ is low for a generated observation, it should not look like it has been drawn from $p_{data}$. 
	- *Generation*: It should not be possible to easily sample a new observation from $p_{model}$.
	- *Representation*: It should be possible to understand how different high-level features are represented by $p_{model}$. 

True data generating distribution $p_{data}$: 

![[Pasted image 20240601071103.png]]
The data-generating rule is simply a uniform distribution over the land mass of the world, with no chance of finding a point in the sea.

Clearly, our model, $p_{model}$, is an oversimplification of $p_{data}$. 
Let us analyze some of the points(indicated in red dots in diagram): 

| Points | Generated by model | Present in Data |
| ------ | ------------------ | --------------- |
| A      | Yes                | No              |
| B      | No                 | Yes             |
| C      | Yes                | Yes             |

Despite its shortcomings, the model is easy to sample from, because it is simply a uni‐ form distribution over the orange box. We can easily choose a point at random from inside this box, in order to sample from it.

Also, we can certainly say that our model is a simple representation of the underlying complex distribution that captures some of the underlying high-level features. The true distribution is separated into areas with lots of land mass (continents) and those with no land mass (the sea). This is a high-level feature that is also true of our model, except we have one large continent, rather than many.
## Representation Learning
Instead of trying to model the high-dimensional sample space directly, 
1. We describe each observation in the training set using some lower-dimensional *latent* space.
2. Learn a mapping function that can take a point in the latent space and map it to a point in the original domain. 
### Example
Training Set: Grayscale images of biscuit tins

![[Pasted image 20240603114939.png]]
2 features uniquely describe each of these tins:
1. Height of tin
2. Width of tin

- We can convert each image of a tin to a point in a latent space of just two dimensions, even though the training set of images is provided in high-dimensional pixel space.

- This means that we can also produce images of tins that do not exist in the training set, by applying a suitable mapping function f to a new point in the latent space.

Realizing that the original dataset can be described by the simpler latent space is not so easy for a machine—it would first need to establish that height and width are the two latent space dimensions that best describe this dataset, then learn the mapping function f that can take a point in this space and map it to a grayscale biscuit tin image. 

![[Pasted image 20240603115158.png]]

One of the benefits of training models that utilize a latent space is that ==we can perform operations that affect high-level properties of the image by manipulating its representation vector within the more manageable latent space.== 
For example, it is not obvious how to adjust the shading of every single pixel to make an image of a biscuit tin taller. However, in the latent space, it’s simply a case of increasing the height latent dimension, then applying the mapping function to return to the image domain. 

The concept of encoding the training dataset into a latent space so that we can sample from it and decode the point back to the original domain is common to many generative modeling techniques.

![[Pasted image 20240603115558.png]]
## Generative Model Taxonomy

3 approaches to model the density function $p_{\theta}(x)$:

![[Pasted image 20240603120003.png]]
### Explicit Modeling
**Aim**: Estimate the probability density directly. 

#### Tractable Modeling
They place constraints on the model architecture, so that the density function has a form that makes it easy to calculate.

#### Approximate Modeling

### Implicit Modeling
**Aim**: Do not estimate the probability density at all, but instead solely focus on producing a stochastic process that directly generates data.












