
Character-level tokenizers are more flexible than word level tokenizers as they bypass the OOV(Out of Vocabulary) issue.

However to capture the context of each word we need to use much longer sequences and this results in loss of performance.



